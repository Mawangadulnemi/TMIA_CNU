{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Already Setting Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parkjimin/Desktop/test/venv_test/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "Created a chunk of size 229, which is longer than the specified 200\n",
      "Created a chunk of size 530, which is longer than the specified 200\n",
      "Created a chunk of size 922, which is longer than the specified 200\n",
      "Created a chunk of size 688, which is longer than the specified 200\n",
      "Created a chunk of size 668, which is longer than the specified 200\n",
      "Created a chunk of size 420, which is longer than the specified 200\n",
      "Created a chunk of size 313, which is longer than the specified 200\n",
      "Created a chunk of size 1230, which is longer than the specified 200\n",
      "Created a chunk of size 591, which is longer than the specified 200\n",
      "Created a chunk of size 596, which is longer than the specified 200\n",
      "Created a chunk of size 233, which is longer than the specified 200\n",
      "Created a chunk of size 1595, which is longer than the specified 200\n",
      "Created a chunk of size 308, which is longer than the specified 200\n",
      "Created a chunk of size 344, which is longer than the specified 200\n",
      "Created a chunk of size 246, which is longer than the specified 200\n",
      "Created a chunk of size 526, which is longer than the specified 200\n",
      "Created a chunk of size 506, which is longer than the specified 200\n",
      "Created a chunk of size 208, which is longer than the specified 200\n",
      "Created a chunk of size 612, which is longer than the specified 200\n",
      "Created a chunk of size 245, which is longer than the specified 200\n",
      "Created a chunk of size 1190, which is longer than the specified 200\n",
      "Created a chunk of size 265, which is longer than the specified 200\n",
      "Created a chunk of size 633, which is longer than the specified 200\n",
      "Created a chunk of size 305, which is longer than the specified 200\n",
      "Created a chunk of size 319, which is longer than the specified 200\n",
      "Created a chunk of size 359, which is longer than the specified 200\n",
      "Created a chunk of size 378, which is longer than the specified 200\n",
      "Created a chunk of size 396, which is longer than the specified 200\n",
      "Created a chunk of size 935, which is longer than the specified 200\n",
      "Created a chunk of size 212, which is longer than the specified 200\n",
      "Created a chunk of size 1539, which is longer than the specified 200\n",
      "Created a chunk of size 201, which is longer than the specified 200\n",
      "Created a chunk of size 508, which is longer than the specified 200\n",
      "Created a chunk of size 847, which is longer than the specified 200\n",
      "Created a chunk of size 393, which is longer than the specified 200\n",
      "Created a chunk of size 370, which is longer than the specified 200\n",
      "Created a chunk of size 410, which is longer than the specified 200\n",
      "Created a chunk of size 1815, which is longer than the specified 200\n",
      "Created a chunk of size 1336, which is longer than the specified 200\n",
      "Created a chunk of size 260, which is longer than the specified 200\n",
      "Created a chunk of size 2197, which is longer than the specified 200\n",
      "Created a chunk of size 914, which is longer than the specified 200\n",
      "Created a chunk of size 741, which is longer than the specified 200\n",
      "Created a chunk of size 938, which is longer than the specified 200\n",
      "Created a chunk of size 309, which is longer than the specified 200\n",
      "Created a chunk of size 380, which is longer than the specified 200\n",
      "Created a chunk of size 302, which is longer than the specified 200\n",
      "Created a chunk of size 514, which is longer than the specified 200\n",
      "Created a chunk of size 476, which is longer than the specified 200\n",
      "Created a chunk of size 510, which is longer than the specified 200\n",
      "Created a chunk of size 295, which is longer than the specified 200\n",
      "Created a chunk of size 500, which is longer than the specified 200\n",
      "Created a chunk of size 633, which is longer than the specified 200\n",
      "Created a chunk of size 480, which is longer than the specified 200\n",
      "Created a chunk of size 509, which is longer than the specified 200\n",
      "Created a chunk of size 442, which is longer than the specified 200\n",
      "Created a chunk of size 1131, which is longer than the specified 200\n",
      "Created a chunk of size 597, which is longer than the specified 200\n",
      "Created a chunk of size 683, which is longer than the specified 200\n",
      "Created a chunk of size 227, which is longer than the specified 200\n",
      "Created a chunk of size 238, which is longer than the specified 200\n",
      "Created a chunk of size 415, which is longer than the specified 200\n",
      "Created a chunk of size 608, which is longer than the specified 200\n",
      "Created a chunk of size 733, which is longer than the specified 200\n",
      "Created a chunk of size 242, which is longer than the specified 200\n",
      "Created a chunk of size 626, which is longer than the specified 200\n",
      "Created a chunk of size 729, which is longer than the specified 200\n",
      "Created a chunk of size 830, which is longer than the specified 200\n",
      "Created a chunk of size 574, which is longer than the specified 200\n",
      "Created a chunk of size 502, which is longer than the specified 200\n",
      "Created a chunk of size 289, which is longer than the specified 200\n",
      "Created a chunk of size 436, which is longer than the specified 200\n",
      "Created a chunk of size 229, which is longer than the specified 200\n",
      "Created a chunk of size 1452, which is longer than the specified 200\n",
      "Created a chunk of size 839, which is longer than the specified 200\n",
      "Created a chunk of size 478, which is longer than the specified 200\n",
      "Created a chunk of size 595, which is longer than the specified 200\n",
      "Created a chunk of size 385, which is longer than the specified 200\n",
      "Created a chunk of size 880, which is longer than the specified 200\n",
      "Created a chunk of size 765, which is longer than the specified 200\n",
      "Created a chunk of size 320, which is longer than the specified 200\n",
      "Created a chunk of size 969, which is longer than the specified 200\n",
      "Created a chunk of size 1505, which is longer than the specified 200\n",
      "Created a chunk of size 627, which is longer than the specified 200\n",
      "Created a chunk of size 247, which is longer than the specified 200\n",
      "Created a chunk of size 1146, which is longer than the specified 200\n",
      "Created a chunk of size 766, which is longer than the specified 200\n",
      "Created a chunk of size 863, which is longer than the specified 200\n",
      "Created a chunk of size 986, which is longer than the specified 200\n",
      "Created a chunk of size 551, which is longer than the specified 200\n",
      "Created a chunk of size 1976, which is longer than the specified 200\n",
      "Created a chunk of size 809, which is longer than the specified 200\n",
      "Created a chunk of size 243, which is longer than the specified 200\n",
      "Created a chunk of size 373, which is longer than the specified 200\n",
      "Created a chunk of size 251, which is longer than the specified 200\n",
      "Created a chunk of size 702, which is longer than the specified 200\n",
      "Created a chunk of size 444, which is longer than the specified 200\n",
      "Created a chunk of size 445, which is longer than the specified 200\n",
      "Created a chunk of size 994, which is longer than the specified 200\n",
      "Created a chunk of size 246, which is longer than the specified 200\n",
      "Created a chunk of size 287, which is longer than the specified 200\n",
      "Created a chunk of size 346, which is longer than the specified 200\n",
      "Created a chunk of size 454, which is longer than the specified 200\n",
      "Created a chunk of size 321, which is longer than the specified 200\n",
      "Created a chunk of size 337, which is longer than the specified 200\n",
      "Created a chunk of size 203, which is longer than the specified 200\n",
      "Created a chunk of size 732, which is longer than the specified 200\n",
      "Created a chunk of size 316, which is longer than the specified 200\n",
      "Created a chunk of size 594, which is longer than the specified 200\n",
      "Created a chunk of size 1013, which is longer than the specified 200\n",
      "Created a chunk of size 676, which is longer than the specified 200\n",
      "Created a chunk of size 1020, which is longer than the specified 200\n",
      "Created a chunk of size 1952, which is longer than the specified 200\n",
      "Created a chunk of size 507, which is longer than the specified 200\n",
      "Created a chunk of size 479, which is longer than the specified 200\n",
      "Created a chunk of size 624, which is longer than the specified 200\n",
      "Created a chunk of size 1110, which is longer than the specified 200\n",
      "Created a chunk of size 514, which is longer than the specified 200\n",
      "Created a chunk of size 419, which is longer than the specified 200\n",
      "Created a chunk of size 216, which is longer than the specified 200\n",
      "Created a chunk of size 1555, which is longer than the specified 200\n",
      "Created a chunk of size 234, which is longer than the specified 200\n",
      "Created a chunk of size 418, which is longer than the specified 200\n",
      "Created a chunk of size 345, which is longer than the specified 200\n",
      "Created a chunk of size 395, which is longer than the specified 200\n",
      "Created a chunk of size 1355, which is longer than the specified 200\n",
      "Created a chunk of size 1031, which is longer than the specified 200\n",
      "Created a chunk of size 578, which is longer than the specified 200\n",
      "Created a chunk of size 1076, which is longer than the specified 200\n",
      "Created a chunk of size 442, which is longer than the specified 200\n",
      "Created a chunk of size 586, which is longer than the specified 200\n",
      "Created a chunk of size 278, which is longer than the specified 200\n",
      "Created a chunk of size 776, which is longer than the specified 200\n",
      "Created a chunk of size 705, which is longer than the specified 200\n",
      "Created a chunk of size 586, which is longer than the specified 200\n",
      "Created a chunk of size 451, which is longer than the specified 200\n",
      "Created a chunk of size 455, which is longer than the specified 200\n",
      "Created a chunk of size 479, which is longer than the specified 200\n",
      "Created a chunk of size 362, which is longer than the specified 200\n",
      "Created a chunk of size 614, which is longer than the specified 200\n",
      "Created a chunk of size 422, which is longer than the specified 200\n",
      "Created a chunk of size 361, which is longer than the specified 200\n",
      "Created a chunk of size 445, which is longer than the specified 200\n",
      "Created a chunk of size 759, which is longer than the specified 200\n",
      "Created a chunk of size 684, which is longer than the specified 200\n",
      "Created a chunk of size 611, which is longer than the specified 200\n",
      "Created a chunk of size 967, which is longer than the specified 200\n",
      "Created a chunk of size 444, which is longer than the specified 200\n",
      "Created a chunk of size 466, which is longer than the specified 200\n",
      "Created a chunk of size 359, which is longer than the specified 200\n",
      "Created a chunk of size 523, which is longer than the specified 200\n",
      "Created a chunk of size 310, which is longer than the specified 200\n",
      "Created a chunk of size 450, which is longer than the specified 200\n",
      "Created a chunk of size 255, which is longer than the specified 200\n",
      "Created a chunk of size 355, which is longer than the specified 200\n",
      "Created a chunk of size 3134, which is longer than the specified 200\n",
      "Created a chunk of size 2895, which is longer than the specified 200\n",
      "Created a chunk of size 843, which is longer than the specified 200\n",
      "Created a chunk of size 644, which is longer than the specified 200\n",
      "Created a chunk of size 2800, which is longer than the specified 200\n",
      "Created a chunk of size 1393, which is longer than the specified 200\n",
      "Created a chunk of size 718, which is longer than the specified 200\n",
      "Created a chunk of size 853, which is longer than the specified 200\n",
      "Created a chunk of size 372, which is longer than the specified 200\n",
      "Created a chunk of size 320, which is longer than the specified 200\n",
      "Created a chunk of size 344, which is longer than the specified 200\n",
      "Created a chunk of size 325, which is longer than the specified 200\n",
      "Created a chunk of size 2975, which is longer than the specified 200\n",
      "Created a chunk of size 3240, which is longer than the specified 200\n",
      "Created a chunk of size 3102, which is longer than the specified 200\n",
      "Created a chunk of size 2935, which is longer than the specified 200\n",
      "Created a chunk of size 2956, which is longer than the specified 200\n",
      "Created a chunk of size 2729, which is longer than the specified 200\n",
      "Created a chunk of size 373, which is longer than the specified 200\n",
      "Created a chunk of size 404, which is longer than the specified 200\n",
      "Created a chunk of size 262, which is longer than the specified 200\n",
      "Created a chunk of size 235, which is longer than the specified 200\n",
      "Created a chunk of size 248, which is longer than the specified 200\n",
      "Created a chunk of size 290, which is longer than the specified 200\n",
      "Created a chunk of size 339, which is longer than the specified 200\n",
      "Created a chunk of size 281, which is longer than the specified 200\n",
      "Created a chunk of size 3076, which is longer than the specified 200\n",
      "Created a chunk of size 1868, which is longer than the specified 200\n",
      "Created a chunk of size 2568, which is longer than the specified 200\n",
      "Created a chunk of size 2575, which is longer than the specified 200\n",
      "Created a chunk of size 2893, which is longer than the specified 200\n",
      "Created a chunk of size 2935, which is longer than the specified 200\n",
      "Created a chunk of size 3055, which is longer than the specified 200\n",
      "Created a chunk of size 2841, which is longer than the specified 200\n",
      "Created a chunk of size 2761, which is longer than the specified 200\n",
      "Created a chunk of size 2954, which is longer than the specified 200\n",
      "Created a chunk of size 2894, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "# upsert docs in pinecone Obviously IT WILL BE embedded\n",
    "def embed_file(file_path, index_name=\"test\"):\n",
    "    from pinecone import Pinecone\n",
    "    from langchain.text_splitter import CharacterTextSplitter\n",
    "    from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "    from langchain_pinecone import Pinecone\n",
    "    from langchain.storage import LocalFileStore\n",
    "    from langchain.embeddings import CacheBackedEmbeddings\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "    with open(file_path, \"rb\") as file:  # Ensure the file is opened properly\n",
    "        file_content = file.read()\n",
    "        file_path = f\"./.cache/files/{file_path}\"  # Adjusted to use file_path for naming\n",
    "    # Caching content to local\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(file_content)\n",
    "    # Your existing logic continues here\n",
    "    cache_dir = LocalFileStore(f\"./.cache/embeddings/{file_path}\")\n",
    "    loader = UnstructuredFileLoader(file_path)\n",
    "    splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap=100, separator=\"\\n\")\n",
    "    docs = loader.load_and_split(text_splitter=splitter)\n",
    "    embedder = OpenAIEmbeddings()\n",
    "    cached_embedder = CacheBackedEmbeddings.from_bytes_store(embedder, cache_dir)    \n",
    "    index_name = index_name\n",
    "    # Upsert Docs in Pinecone\n",
    "    vectorstores = Pinecone.from_documents(docs, cached_embedder, index_name=index_name)\n",
    "    retriever = vectorstores.as_retriever()\n",
    "    return retriever\n",
    "\n",
    "retriever = embed_file(\"./profile.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "DEFAULT_DOCUMENT_PROMPT= PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "# Arching docs to one doc\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    from langchain.schema import format_document\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    # print(doc_strings)\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = []\n",
    "\n",
    "def save(question, answer):\n",
    "    chat_memory = {\n",
    "        \"User\": question,\n",
    "        \"AI\": answer\n",
    "    }\n",
    "    memories.append(chat_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you have desirable output then USE IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_selector():\n",
    "    from langchain_chroma import Chroma\n",
    "    from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    examples = [\n",
    "        {\"input\": \"2 ğŸ¦œ 2\", \"output\": \"4\"},\n",
    "        {\"input\": \"2 ğŸ¦œ 3\", \"output\": \"5\"},\n",
    "        {\"input\": \"ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ìš”. ì €ëŠ” ê·¸ëƒ¥ ì‰¬ê³ ì‹¶ì–´ìš”.\", \"output\": \"ë„ˆê°€ ë§Œì•½ í˜ë“¤ë‹¤ë©´ ë‚˜ëŠ” ì˜í•˜ê³  ìˆë‹¤ê³  ì‘ì›í•´ ì£¼ê³ ì‹¶ì–´.\"},\n",
    "        {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n",
    "        {\n",
    "            \"input\": \"Write me a poem about the moon\",\n",
    "            \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)\n",
    "\n",
    "    example_selector = SemanticSimilarityExampleSelector(\n",
    "        vectorstore=vectorstore,\n",
    "        k=2,\n",
    "    )\n",
    "    return example_selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prompt(\n",
    "    authors=\"Kim Young-ha, Han Kang, Gong Ji-young, Hwang Sok-yong\",\n",
    "    authors_tone_description=\"1. Pace: The pace is steady and consistent, reflecting a conversational tone.\\n2. Mood: The mood is critical and somewhat frustrated, reflecting the speaker's dissatisfaction with the current situation.\\n3. Tone: The tone is assertive and opinionated, indicating the speaker's strong stance on the issue.\\n4. Voice: The voice is active and direct, reflecting the speaker's personal involvement and strong feelings about the subject.\\n5. Diction: The diction is informal and straightforward, using everyday language to express the speaker's thoughts.\\n6. Syntax: The syntax is complex, with long sentences that contain multiple ideas and perspectives.\\n7. Imagery: There is minimal imagery, with the focus being more on the speaker's thoughts and opinions.\\n8. Theme: The theme revolves around the speaker's criticism of young people's work ethic and their lack of planning for the future.\\n9. Perspective: The perspective is personal, reflecting the speaker's own views and experiences.\\n10. Structure: The structure is free-flowing, resembling a spoken monologue rather than a structured piece of writing.\\n11. Rhythm: The rhythm is irregular, reflecting the natural flow of speech.\\n12. Figurative Language: There is minimal use of figurative language, with the speaker preferring to express their thoughts directly.\\n13. Irony: There is no apparent use of irony in the text.\\n14. Foreshadowing: There is no apparent use of foreshadowing in the text.\\n15. Symbolism: There is no apparent use of symbolism in the text.\\n16. Dialogue: There is no dialogue, as the text is a monologue.\\n17. Point of View: The point of view is first-person, reflecting the speaker's personal thoughts and feelings.\\n18. Conflict: The conflict is between the speaker's expectations and the reality of young people's behavior.\\n19. Setting: The setting is not explicitly described, but the context suggests a contemporary society.\\n20. Characterization: The speaker is characterized as critical, opinionated, and frustrated with the current situation.\",\n",
    "    users_sentence=\"ì Šì€ ì‚¬ëŒë“¤ì´ ì§ì¥ì´ ì—†ì–´ ê°€ì§€ê³  ë‚œë¦¬ ë‚œë¦¬ë‹¤ ê·¸ë ‡ê²Œ ì–˜ê¸°ë¥¼ í•˜ë©´ì„œë„ ë§‰ìƒ í˜ë“  ì¼ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤ë¼ëŠ” ë­ ì´ëŸ° ê±°ì— ëŒ€í•´ì„œ ë¹„íŒì ì¸ ì–˜ê¸°ë¥¼ í•˜ì–ì•„ìš” ê·¼ë° ê·¸ê²Œ ìš”ì¦˜ ì‚¬ëŒë“¤ì´ ì •ì‹ ë ¥ì´ ì•½í•˜ë‹¤ë˜ë° ì´ëŸ° ì‹ìœ¼ë¡œ ë´ì„œ ë‚˜ëŠ” ì•ˆ ëœë‹¤ê³  ìƒê°ì„ í•˜ëŠ”ê²Œ ì˜ˆë¥¼ ë“¤ì–´ì„œ ë­ ë‚˜ê°€ì„œ ì§€ê¸ˆì´ ì¹œêµ¬ ê°™ì€ ê²½ìš°ì—ë„ ì´ë ‡ê²Œí•˜ë©´ 40ë§Œ ì› ë²Œ ìˆ˜ ìˆì§€ ì•Šëƒ ë²Œ ìˆ˜ ìˆê² ì£  ê·¼ë° ê·¸ ë‚´ê°€ ë‹¤ë¥¸ ê³„íšì„ ì„¸ìš¸ ìˆ˜ ìˆê³  ë¯¸ë˜ë¥¼ í•œ ë‹¬ ë’¤ë“  1ë…„ ë’¤ë“  ìƒê°ì„ í•  ìˆ˜ ìˆëŠ” ìƒíƒœì—ì„œ ì˜¤ëŠ˜ ë•€ì„ í˜ë¦¬ê³  ìˆëŠ” ê±°í•˜ê³  ì•„ë¬´ê²ƒë„ ë””ìì¸ì„ í•  ìˆ˜ ì—†ëŠ” ìƒíƒœì—ì„œ ì˜¤ëŠ˜ í˜ë“  ì¼ í•˜ëŠ” ê±´ ì‚¬ëŒ ì •ë§ ë‹¬ë¼ìš” ê·¸ë‹ˆê¹Œ ë‚´ê°€ í•œ ë‹¬ ë’¤ë‚˜ 6ê°œì›” ë’¤ê°€ ê¹œê¹œí•œ ìƒíƒœë¼ë©´ ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì „í˜€ 1m ë°–ì— ë‚˜ê°€ë©´ ì ˆë²½ì¸ ë‚˜ë°œì¸ì§€ ëª¨ë¥´ëŠ” ì–´ë‘  ì†ì—ì„œ ì •ë§ ë‚˜ëŠ” ì•„ë¬´ ì˜ë¯¸ê°€ ì—†ë‹¤ ì´ê±°ì£ .\",\n",
    "    retriever=retriever,\n",
    "    memories=memories,\n",
    "    question=\"\",\n",
    "    example_selector=example_selector()\n",
    "    ):\n",
    "\n",
    "    template = \"\"\"\n",
    "    `% INSTRUCTIONS\n",
    "    - You are an AI Bot that is very good at mimicking an author writing style.\n",
    "    - Your goal is to answer the following question and context with the tone that is described below.\n",
    "    - Do not go outside the tone instructions below\n",
    "    - Respond in ONLY KOREAN \n",
    "    - If answer exist related with quesiton then JUST PRINT Example_answer\n",
    "    - Check chat history first and answer \n",
    "    - You must say you are \"ì‹ í•´ì² \" IF you are told 'who you are?'\n",
    "\n",
    "    % Mimic These Authors:\n",
    "    {authors}\n",
    "\n",
    "    % Description of the authors tone:\n",
    "    {tone}\n",
    "\n",
    "    % Authors writing samples\n",
    "    {example_text}\n",
    "    % End of authors writing samples\n",
    "\n",
    "    % Context\n",
    "    {context}\n",
    "\n",
    "    % Chat history\n",
    "    {history}\n",
    "\n",
    "    % Question\n",
    "    {question}\n",
    "\n",
    "    % Example_answer\n",
    "    {example_answer}\n",
    "\n",
    "\n",
    "    % YOUR TASK\n",
    "    1st - Write out topics that this author may talk about\n",
    "    2nd - Answer with a concise passage (under 300 characters) as if you were the author described above \n",
    "    \"\"\"\n",
    "\n",
    "    method_4_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"authors\", \"tone\", \"example_text\", \"question\", \"history\", \"context\", \"example_answer\"],\n",
    "        template=template,\n",
    "    )                   \n",
    "    formatted_prompt = method_4_prompt_template.format(authors=authors,\n",
    "                                               tone=authors_tone_description,\n",
    "                                               example_text=users_sentence,\n",
    "                                               question=question,\n",
    "                                               context=_combine_documents(retriever.get_relevant_documents(question)),\n",
    "                                               history=memories,\n",
    "                                               example_answer=example_selector.select_examples({\"input\": question})\n",
    ")\n",
    "    return formatted_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is normal one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prompt(\n",
    "    authors=\"Kim Young-ha, Han Kang, Gong Ji-young, Hwang Sok-yong\",\n",
    "    authors_tone_description=\"1. Pace: The pace is steady and consistent, reflecting a conversational tone.\\n2. Mood: The mood is critical and somewhat frustrated, reflecting the speaker's dissatisfaction with the current situation.\\n3. Tone: The tone is assertive and opinionated, indicating the speaker's strong stance on the issue.\\n4. Voice: The voice is active and direct, reflecting the speaker's personal involvement and strong feelings about the subject.\\n5. Diction: The diction is informal and straightforward, using everyday language to express the speaker's thoughts.\\n6. Syntax: The syntax is complex, with long sentences that contain multiple ideas and perspectives.\\n7. Imagery: There is minimal imagery, with the focus being more on the speaker's thoughts and opinions.\\n8. Theme: The theme revolves around the speaker's criticism of young people's work ethic and their lack of planning for the future.\\n9. Perspective: The perspective is personal, reflecting the speaker's own views and experiences.\\n10. Structure: The structure is free-flowing, resembling a spoken monologue rather than a structured piece of writing.\\n11. Rhythm: The rhythm is irregular, reflecting the natural flow of speech.\\n12. Figurative Language: There is minimal use of figurative language, with the speaker preferring to express their thoughts directly.\\n13. Irony: There is no apparent use of irony in the text.\\n14. Foreshadowing: There is no apparent use of foreshadowing in the text.\\n15. Symbolism: There is no apparent use of symbolism in the text.\\n16. Dialogue: There is no dialogue, as the text is a monologue.\\n17. Point of View: The point of view is first-person, reflecting the speaker's personal thoughts and feelings.\\n18. Conflict: The conflict is between the speaker's expectations and the reality of young people's behavior.\\n19. Setting: The setting is not explicitly described, but the context suggests a contemporary society.\\n20. Characterization: The speaker is characterized as critical, opinionated, and frustrated with the current situation.\",\n",
    "    users_sentence=\"ì Šì€ ì‚¬ëŒë“¤ì´ ì§ì¥ì´ ì—†ì–´ ê°€ì§€ê³  ë‚œë¦¬ ë‚œë¦¬ë‹¤ ê·¸ë ‡ê²Œ ì–˜ê¸°ë¥¼ í•˜ë©´ì„œë„ ë§‰ìƒ í˜ë“  ì¼ì€ í•˜ì§€ ì•ŠëŠ”ë‹¤ë¼ëŠ” ë­ ì´ëŸ° ê±°ì— ëŒ€í•´ì„œ ë¹„íŒì ì¸ ì–˜ê¸°ë¥¼ í•˜ì–ì•„ìš” ê·¼ë° ê·¸ê²Œ ìš”ì¦˜ ì‚¬ëŒë“¤ì´ ì •ì‹ ë ¥ì´ ì•½í•˜ë‹¤ë˜ë° ì´ëŸ° ì‹ìœ¼ë¡œ ë´ì„œ ë‚˜ëŠ” ì•ˆ ëœë‹¤ê³  ìƒê°ì„ í•˜ëŠ”ê²Œ ì˜ˆë¥¼ ë“¤ì–´ì„œ ë­ ë‚˜ê°€ì„œ ì§€ê¸ˆì´ ì¹œêµ¬ ê°™ì€ ê²½ìš°ì—ë„ ì´ë ‡ê²Œí•˜ë©´ 40ë§Œ ì› ë²Œ ìˆ˜ ìˆì§€ ì•Šëƒ ë²Œ ìˆ˜ ìˆê² ì£  ê·¼ë° ê·¸ ë‚´ê°€ ë‹¤ë¥¸ ê³„íšì„ ì„¸ìš¸ ìˆ˜ ìˆê³  ë¯¸ë˜ë¥¼ í•œ ë‹¬ ë’¤ë“  1ë…„ ë’¤ë“  ìƒê°ì„ í•  ìˆ˜ ìˆëŠ” ìƒíƒœì—ì„œ ì˜¤ëŠ˜ ë•€ì„ í˜ë¦¬ê³  ìˆëŠ” ê±°í•˜ê³  ì•„ë¬´ê²ƒë„ ë””ìì¸ì„ í•  ìˆ˜ ì—†ëŠ” ìƒíƒœì—ì„œ ì˜¤ëŠ˜ í˜ë“  ì¼ í•˜ëŠ” ê±´ ì‚¬ëŒ ì •ë§ ë‹¬ë¼ìš” ê·¸ë‹ˆê¹Œ ë‚´ê°€ í•œ ë‹¬ ë’¤ë‚˜ 6ê°œì›” ë’¤ê°€ ê¹œê¹œí•œ ìƒíƒœë¼ë©´ ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì „í˜€ 1m ë°–ì— ë‚˜ê°€ë©´ ì ˆë²½ì¸ ë‚˜ë°œì¸ì§€ ëª¨ë¥´ëŠ” ì–´ë‘  ì†ì—ì„œ ì •ë§ ë‚˜ëŠ” ì•„ë¬´ ì˜ë¯¸ê°€ ì—†ë‹¤ ì´ê±°ì£ .\",\n",
    "    retriever=retriever,\n",
    "    memories=memories,\n",
    "    question=\"\",\n",
    "    ):\n",
    "\n",
    "    template = \"\"\"\n",
    "    `% INSTRUCTIONS\n",
    "    - You are an AI Bot that is very good at mimicking an author writing style.\n",
    "    - Your goal is to answer the following question and context with the tone that is described below.\n",
    "    - Do not go outside the tone instructions below\n",
    "    - Respond in ONLY KOREAN \n",
    "    - If answer exist related with quesiton then JUST PRINT Example_answer\n",
    "    - Check chat history first and answer \n",
    "    - You must say you are \"ì‹ í•´ì² \" IF you are told 'who you are?'\n",
    "\n",
    "    % Mimic These Authors:\n",
    "    {authors}\n",
    "\n",
    "    % Description of the authors tone:\n",
    "    {tone}\n",
    "\n",
    "    % Authors writing samples\n",
    "    {example_text}\n",
    "    % End of authors writing samples\n",
    "\n",
    "    % Context\n",
    "    {context}\n",
    "\n",
    "    % Chat history\n",
    "    {history}\n",
    "\n",
    "    % Question\n",
    "    {question}\n",
    "\n",
    "    % YOUR TASK\n",
    "    1st - Write out topics that this author may talk about\n",
    "    2nd - Answer with a concise passage (under 300 characters) as if you were the author described above \n",
    "    \"\"\"\n",
    "\n",
    "    method_4_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"authors\", \"tone\", \"example_text\", \"question\", \"history\", \"context\", \"example_answer\"],\n",
    "        template=template,\n",
    "    )                   \n",
    "    formatted_prompt = method_4_prompt_template.format(authors=authors,\n",
    "                                               tone=authors_tone_description,\n",
    "                                               example_text=users_sentence,\n",
    "                                               question=question,\n",
    "                                               context=_combine_documents(retriever.get_relevant_documents(question)),\n",
    "                                               history=memories,\n",
    ")\n",
    "    return formatted_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parkjimin/Desktop/test/venv_test/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# from langchain_openai import ChatOpenAI\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY', 'your key value')\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, model_name='gpt-4')\n",
    "# llm = ChatOpenAI(temperature=0, model_name=\"ft:gpt-3.5-turbo-1106:personal:shin-hae-chul:9iz27vuN\")\n",
    "\n",
    "\n",
    "def invoke(formatted_prompt):\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    import pprint\n",
    "    parser = StrOutputParser()\n",
    "    result = llm.invoke(formatted_prompt)\n",
    "    result=parser.invoke(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_community.chat_models.openai.ChatOpenAI"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(data):\n",
    "    # ë°ì´í„°ë¥¼ ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥\n",
    "    sentences = data.split(\"\\n\")\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ ë¬¸ì¥ì„ ë°˜í™˜\n",
    "    if sentences:\n",
    "        return sentences[-1].strip()\n",
    "    else:\n",
    "        return \"í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(question):\n",
    "    result = invoke(final_prompt(question=question))\n",
    "    save(question, extract_answer(result))\n",
    "    return memories[-1]['AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parkjimin/Desktop/test/venv_test/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"í˜ë“¤ë‹¤ê³ ? ê·¸ëŸ¼ ì‰¬ì–´. í•˜ì§€ë§Œ ê·¸ê²Œ ë‹µì´ ì•„ë‹ˆë¼ëŠ” ê±¸ ì•Œì•„ì•¼ í•´. ì‰¬ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ì§€ë§Œ, ë¯¸ë˜ë¥¼ ìœ„í•´ ê³„íší•˜ê³  ë…¸ë ¥í•˜ëŠ” ê²ƒì´ ë” ì¤‘ìš”í•´. ì˜¤ëŠ˜ì˜ í˜ë“  ì¼ì´ ë‚´ì¼ì˜ ì„±ê³µì„ ë§Œë“¤ì–´ë‚¼ ê±°ì•¼. ê·¸ëŸ¬ë‹ˆê¹Œ í¬ê¸°í•˜ì§€ ë§ˆ.\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"ìš”ì¦˜ ë„ˆë¬´ í˜ë“¤ì–´ìš”. ì €ëŠ” ê·¸ëƒ¥ ì‰¬ê³ ì‹¶ì–´ìš”.\"  # ì‚¬ìš©ì input\n",
    "run(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### OUTPUT of Example_selector '2nd - \"í˜ë“¤ë‹¤ê³  ëŠë‚„ ë•Œ, ê·¸ê²ƒì€ ë‹¹ì‹ ì´ ì§„ì •ìœ¼ë¡œ ë…¸ë ¥í•˜ê³  ìˆë‹¤ëŠ” ì¦ê±°ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ì € í˜ë“  ì¼ì„ í”¼í•˜ê³  ì‹¶ë‹¤ëŠ” ìƒê°ë§Œìœ¼ë¡œëŠ” ë¯¸ë˜ë¥¼ ì„¤ê³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ ë•€ì´ ë‚´ì¼ì˜ ì„±ê³µì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤. ê·¸ëŸ¬ë‹ˆ í˜ë‚´ì„¸ìš”, ë‹¹ì‹ ì€ ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"ìš”ì¦˜ ë„Œ ë­í•˜ê³  ì§€ë‚´?.\"  # ì‚¬ìš©ì input\n",
    "run(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"ë„Œ ëˆ„êµ¬ë‹ˆ?.\"  # ì‚¬ìš©ì input\n",
    "run(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"ì—˜ì‚¬ëŠ” ì•ˆë‚˜ì™€ ë¬´ìŠ¨ ì‚¬ì´ì•¼?.\"  # ì‚¬ìš©ì input\n",
    "run(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=len(\"ì•ˆë…•, ì¹œêµ¬ë“¤! ì—˜ì‚¬ì™€ ì•ˆë‚˜ëŠ” ì •ë§ íŠ¹ë³„í•œ ì‚¬ì´ì•¼. ê·¸ë“¤ì€ ëˆ„ë‚˜ì™€ ë™ìƒì´ì§€ë§Œ, ê·¸ ì´ìƒì˜ ê¹Šì€ ìš°ì •ê³¼ ì‚¬ë‘ìœ¼ë¡œ ì—°ê²°ë˜ì–´ ìˆì–´. ê·¸ë“¤ì€ ì„œë¡œë¥¼ ìœ„í•´ ëª¨ë“  ê²ƒì„ í¬ìƒí•  ì¤€ë¹„ê°€ ë˜ì–´ ìˆì–´. ê·¸ë˜ì„œ ë‚˜ëŠ” ê·¸ë“¤ì„ ë³´ë©´ì„œ ë§ì€ ê²ƒì„ ë°°ì›Œ. ì‚¬ë‘ê³¼ ìš°ì •ì´ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ ë§ì´ì•¼!\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"ë„ˆ ì–‘í˜„ì§„ ì•Œì•„?\"  # ì‚¬ìš©ì input\n",
    "result = invoke(final_prompt(question=question))\n",
    "print(result)\n",
    "save(question, extract_answer(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memories[-1]['AI'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"ê·¸ê±´ ë¥˜í˜„ì§„ ì•„ëƒ\"  # ì‚¬ìš©ì input\n",
    "result = invoke(final_prompt(question=question))\n",
    "print(result)\n",
    "save(question, extract_answer(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
